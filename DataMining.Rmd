---
title: "Case Studies in Data Mining with R"
author: "曾意儒 Yi-Ju Tseng"
institute: "Chung Gung University"
date: "2020/05/18"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: inverse, center, middle

[yjtseng.info/talk/datamining](https://yjtseng.info/talk/datamining)

---
class: inverse, center, middle
# Reviews
---

## R and RStudio

[R](https://cloud.r-project.org/) : Core (engine)

```{r echo=FALSE,out.height="400px", fig.align='center'}
knitr::include_graphics("https://www.teslarati.com/wp-content/uploads/2018/07/model-3-drivetrain-1.jpg")
```

[Source](https://www.teslarati.com/tesla-patent-more-efficient-electric-motors/)

---
## R and RStudio

[RStudio](https://www.rstudio.com/products/rstudio/download/#download) : IDE (dashboard)

```{r echo=FALSE,out.height="400px", fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/DHLab-TSENG/emr_slide/master/emr_package-figure/dashboard.jpg")
```

[Source](https://www.theverge.com/2015/3/19/8260295/tesla-user-interface-redesign-concept)

---

## How to use RStudio 
.pull-left[
4 Blocks in RStudio：
- Source editor  -> edit the codes here
- Console -> get the results here
]
.pull-right[
</br>
- Environment/...
- File/Figure/...
]

```{r echo=FALSE,out.height="350px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/DHLab-TSENG/emr_slide/master/emr_package-figure/RStudio.png")
```

---
## R and R Packages

R : Core (iPhone)

```{r echo=FALSE,out.height = "400px",fig.align='center'}
knitr::include_graphics("https://store.storeimages.cdn-apple.com/4982/as-images.apple.com/is/iphone-xr-white-select-201809?wid=940&hei=1112&fmt=png-alpha&qlt=80&.v=1551226036668")
```

---
## R and R Packages

R Packages : APP

```{r echo=FALSE,out.height = "400px",fig.align='center'}
knitr::include_graphics("https://3c.yipee.cc/wp-content/uploads/2019/06/a7ffbaa3df50d7cafe6801a8a8d7a3bf-620x320.jpg")
```

[Source](https://www.apple.com/)

---
## Install and Use Packages

- Install

```{r tidy=FALSE, eval=FALSE}
install.packages("tidymodels")  #<<
library(tidymodels)
```

--


- Use

```{r tidy=FALSE, eval=FALSE}
install.packages("tidymodels")  
library(tidymodels) #<<
```
```{r echo=F}
library(tidymodels)
```

---
## Pipe %>%

- 處理資料流的方法
- 將資料（輸出）丟到後方函數中

---
## 主角: tidymodels套件

- 由`caret`套件的開發者Max Kuhn所帶領開發的全新建模架構
- 將建模必要流程包裝成套件組，模組化各必要流程
- 整合多種建模演算法套件，單一窗口與語法
- 撰寫邏輯和方法與tidyverse套件組合相同
- 若熟悉dplyr、ggplot等套件應該蠻好上手

第一次使用前一樣要先安裝

```{r eval=F}
install.packages("tidymodels")
```

安裝後即可載入
```{r eval=F}
library(tidymodels)
```

---

class: inverse, center, middle

# Get Started - Data Import

---

## 建模範例資料 - 載入

- `mlbench`套件內附的`PimaIndiansDiabetes2`資料集
- Outcome為是否有糖尿病  **diabetes**欄位
- 可輸入`?PimaIndiansDiabetes2`查看所有欄位變數

```{r}
library(mlbench)
data("PimaIndiansDiabetes2") # 載入資料
```
---

## 建模範例資料 - 初探

- 用`glimpse()`函數看一下各資料的**型態**跟資料**筆數**
```{r}
glimpse(PimaIndiansDiabetes2)
```
- 發現有不少空值，要決定如何處理

---

## 建模範例資料 - Outcome比例

- 在處理空值前，先看**diabetes**欄位中有病跟沒病的人數與比例

```{r}
PimaIndiansDiabetes2 %>% 
  count(diabetes) %>% 
  mutate(prop = n/sum(n))
```

- 大概是65:35，有些不平均，但還行

---
## 刪除空（遺漏）值

- 臨床研究通常會刪除有**缺值**的資料
- 為了後續敘述性統計方便，若狀況許可，會在第一步刪除資料
- 某些演算法不能用有空值的資料建模


```{r}
PimaIndiansDiabetes2<-
  PimaIndiansDiabetes2 %>% #<<
  filter(complete.cases(PimaIndiansDiabetes2)) 
```


---
## 刪除遺漏值

- 臨床研究通常會刪除有**缺值**的資料
- 為了後續敘述性統計方便，若狀況許可，會在第一步刪除資料
- 某些演算法不能用有空值的資料建模


```{r}
PimaIndiansDiabetes2<-
  PimaIndiansDiabetes2 %>% 
  filter(complete.cases(PimaIndiansDiabetes2)) #<<
```

- `filter()`為`dplyr`套件的功能，可針對資料列(row)做子集

--

.pull-left[
```{r echo=F}
knitr::kable(data.frame(ID=1:3,Name=letters[1:3]))
```
]
--
.pull-right[
```{r echo=F}
knitr::kable(data.frame(ID=c(1,3),Name=letters[c(1,3)]))
```
]

---
## 刪除遺漏值

- 臨床研究通常會刪除有缺值的資料
- 為了後續敘述性統計方便，若狀況許可，會在第一步刪除資料
- 某些演算法不能用有空值的資料建模


```{r}
PimaIndiansDiabetes2<-
  PimaIndiansDiabetes2 %>% 
  filter(complete.cases(PimaIndiansDiabetes2)) #<<
```

- `filter()`為`dplyr`套件的功能，可針對資料列(row)做子集
- 用`complete.cases()`辨識是否為完整資料，若沒有空值，回傳TRUE

---
## 刪除遺漏值後 - Outcome比例

刪除空後資料筆數有些微改變，但大概還是6x:3x的比例

```{r}
PimaIndiansDiabetes2 %>% 
  count(diabetes) %>% 
  mutate(prop = n/sum(n))
```

---
class: inverse, center, middle

# 敘述性統計

---
## 醫學資料分析中的敘述性統計
- 通常是論文中的必要表格
- 描述有病沒病的兩群人的基本資料，並做**統計檢定**
```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneExample.png")
```
[Source](https://www.sciencedirect.com/science/article/abs/pii/S1386505618311213)

---
## 單變量分析
- 使用`tableone`套件完成表格，第一次使用前要先安裝
- 將去除空值的資料`PimaIndiansDiabetes2`放入`CreateTableOne()`函數
```{r}
library(tableone)
tableone<-
  CreateTableOne(data=PimaIndiansDiabetes2)#<<
print(tableone)
```
- [tableone使用說明](https://cran.r-project.org/web/packages/tableone/vignettes/introduction.html)

---
## 單變量分析 - 依outcome分組

```{r}
library(tableone)
tableone<-
  CreateTableOne(data=PimaIndiansDiabetes2,
                 strata = "diabetes")#<<
print(tableone)
```

---
## 單變量分析 - 貼到Excel的表格

```{r}
library(tableone)
tableone<-
  CreateTableOne(data=PimaIndiansDiabetes2,
                 strata = "diabetes")
print(tableone,quote = T)#<<
```

---
## 單變量分析 - Excel處理步驟 (1/7)

調整Console視窗大小，讓結果不被強迫換行

```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneR.png")
```

---
## 單變量分析 - Excel處理步驟 (2/7)

全選表格

```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneRSelect.png")
```

---
## 單變量分析 - Excel處理步驟 (3/7)

打開Excel貼上
```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneRExcel.png")
```

---
## 單變量分析 - Excel處理步驟 (4/7)
打開Excel->資料->資料剖析功能
```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneRExcelFormat.png")
```

---
## 單變量分析 - Excel處理步驟 (5/7)
設定使用分隔符號切割資料
```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneRExcelDel.png")
```

---
## 單變量分析 - Excel處理步驟 (6/7)
用空格當作分隔符號，並將文字辨識符號設為雙引號
```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneRExcelDelSetting.png")
```


---
## 單變量分析 - Excel處理步驟 (7/7)
完成！！
```{r echo=FALSE,out.height="400px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/yijutseng/RCourses/master/figures/tableoneFinal.png")
```

---
class: inverse, center, middle

# 開始建模 - 策略說明與資料分割

---

## 訓練/調整與驗證模型效能策略
How to Read Articles That Use Machine Learning - Users’ Guides to the Medical Literature [JAMA](https://jamanetwork.com/journals/jama/fullarticle/2754798)，說明在機器學習時代如何建立預測模型，跟傳統的不同
```{r echo=F,out.height="400px",fig.align='center'}
knitr::include_graphics("https://cdn.jamanetwork.com/ama/content_public/journal/jama/938259/jug190001f2.png?Expires=2147483647&Signature=cU6lP2ZYSdn9MyOakMWobXQF2h6LSPCExTP1q7x74zRH7gDgkRSqshXWADmcQUz0XJVK~aVPK3cb-~shWQ6vd6EF4FwIcR8NBXMlGq1sLDR5dXLwpb~qoEYzXvg03zCz2l0AHmdlFxy4IGYGG3ilBfuPh1SCweskxtaUfsWqGsUcwc6FNo3KjaR9j58eJeZOnBEr6a2OF2m~XlEOnT1W3vaYn2-fuGZLAQR88XcUGWp1LYgc6GnDTO1s7zj5m9mYhlL-CeOaLXQNGrSl6fAvw6LisZW-f2tChvIaDfCd4vuuNw-Q1V6sjm-jgUehMt8wjrc61YW6WqyIC9mF6VGzzg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA")
```
---

## 調整參數的必要性

- 在傳統"非"機器學習模型(圖上半部)，分訓練組與測試組
- 訓練模型時，記得不可以用**測試組**資料來訓練模型，才能得到真實的預測結果 (完全沒偷看答案的意思)
```{r echo=F,out.height="400px",fig.align='center'}
knitr::include_graphics("https://cdn.jamanetwork.com/ama/content_public/journal/jama/938259/jug190001f2.png?Expires=2147483647&Signature=cU6lP2ZYSdn9MyOakMWobXQF2h6LSPCExTP1q7x74zRH7gDgkRSqshXWADmcQUz0XJVK~aVPK3cb-~shWQ6vd6EF4FwIcR8NBXMlGq1sLDR5dXLwpb~qoEYzXvg03zCz2l0AHmdlFxy4IGYGG3ilBfuPh1SCweskxtaUfsWqGsUcwc6FNo3KjaR9j58eJeZOnBEr6a2OF2m~XlEOnT1W3vaYn2-fuGZLAQR88XcUGWp1LYgc6GnDTO1s7zj5m9mYhlL-CeOaLXQNGrSl6fAvw6LisZW-f2tChvIaDfCd4vuuNw-Q1V6sjm-jgUehMt8wjrc61YW6WqyIC9mF6VGzzg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA")
```

---

## 調整參數的必要性
- 在圖下半，主要差異是在訓練模型時多了一組**參數調整資料集**
- 因為在多種機器學習模型中，有可調整的參數
- 為了讓參數調整效果更好，會將訓練組再切分成小組，用來決定**最佳參數**
- 決定**最佳參數**以後，用**訓練組**搭配最佳參數訓練模型，最後用**測試組**測試
```{r echo=F,out.height="400px",fig.align='center'}
knitr::include_graphics("https://cdn.jamanetwork.com/ama/content_public/journal/jama/938259/jug190001f2.png?Expires=2147483647&Signature=cU6lP2ZYSdn9MyOakMWobXQF2h6LSPCExTP1q7x74zRH7gDgkRSqshXWADmcQUz0XJVK~aVPK3cb-~shWQ6vd6EF4FwIcR8NBXMlGq1sLDR5dXLwpb~qoEYzXvg03zCz2l0AHmdlFxy4IGYGG3ilBfuPh1SCweskxtaUfsWqGsUcwc6FNo3KjaR9j58eJeZOnBEr6a2OF2m~XlEOnT1W3vaYn2-fuGZLAQR88XcUGWp1LYgc6GnDTO1s7zj5m9mYhlL-CeOaLXQNGrSl6fAvw6LisZW-f2tChvIaDfCd4vuuNw-Q1V6sjm-jgUehMt8wjrc61YW6WqyIC9mF6VGzzg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA")
```
---

## 調整參數的必要性

本課程範例 :

- **邏輯迴歸Logistic Regression**示範此圖上半部**不調參數**的作法
- **隨機森林Random Forest**示範此圖下半部**需要調整參數**的作法
```{r echo=F,out.height="400px",fig.align='center'}
knitr::include_graphics("https://cdn.jamanetwork.com/ama/content_public/journal/jama/938259/jug190001f2.png?Expires=2147483647&Signature=cU6lP2ZYSdn9MyOakMWobXQF2h6LSPCExTP1q7x74zRH7gDgkRSqshXWADmcQUz0XJVK~aVPK3cb-~shWQ6vd6EF4FwIcR8NBXMlGq1sLDR5dXLwpb~qoEYzXvg03zCz2l0AHmdlFxy4IGYGG3ilBfuPh1SCweskxtaUfsWqGsUcwc6FNo3KjaR9j58eJeZOnBEr6a2OF2m~XlEOnT1W3vaYn2-fuGZLAQR88XcUGWp1LYgc6GnDTO1s7zj5m9mYhlL-CeOaLXQNGrSl6fAvw6LisZW-f2tChvIaDfCd4vuuNw-Q1V6sjm-jgUehMt8wjrc61YW6WqyIC9mF6VGzzg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA")
```


---
## Pre-Step 1. 訓練組、測試組資料分割

- 不管要不要調參數，都需要分割**訓練組**與**測試組**

```{r echo=F,out.height="350px",fig.align='center'}
knitr::include_graphics("https://www.tidymodels.org/start/resampling/img/resampling.svg")
```
[圖片來源](https://www.tidymodels.org/start/resampling/)



---
## Pre-Step 1. 訓練組、測試組資料分割

- 用`initial_split()`函數將資料分成訓練組與測試組
  - 第一個參數放資料`PimaIndiansDiabetes2`
  - 第二個參數`prop`放訓練組測試組比例`(3/4)`
  - 第三個參數`strata`放分組抽樣依據`diabetes`，針對此分組個別抽某個比例的人當訓練組，剩下的就當測試組。

```{r}
set.seed(123)
splits<- initial_split(PimaIndiansDiabetes2,  #<<
                       prop=(3/4),#<<
                       strata = diabetes)#<<
DM_train<- training(splits)
DM_test<- testing(splits)
```

---
## Pre-Step 1. 訓練組、測試組資料分割

- 用`initial_split()`函數將資料分成訓練組與測試組
  - 第一個參數放資料`PimaIndiansDiabetes2`
  - 第二個參數`prop`放訓練組測試組比例`(3/4)`
  - 第三個參數`strata`放分組抽樣依據`diabetes`，針對此分組個別抽某個比例的人當訓練組，剩下的就當測試組。
- 切割完後，用`training()`和`testing()`函數將訓練組測試組正式分開。

```{r}
set.seed(123)
splits<- initial_split(PimaIndiansDiabetes2, 
                       prop=(3/4),
                       strata = diabetes)
DM_train<- training(splits)#<<
DM_test<- testing(splits)#<<
```

---
## Pre-Step 1. 訓練組、測試組資料分割

- `initial_split()`函數有隨機的概念
- 為了讓每次的實驗結果相同，要**在有隨機事件前設定seed** `set.seed()`
- seed為隨機的依據，讓隨機每次都一樣，確保實驗結果可重複

```{r}
set.seed(123)#<<
splits<- initial_split(PimaIndiansDiabetes2, 
                       prop=(3/4),
                       strata = diabetes)
DM_train<- training(splits)
DM_test<- testing(splits)
```
---
## 查看分組結果

.pull-left[
分組完後，查看訓練組的生病比例
```{r}
DM_train %>% 
  count(diabetes) %>% 
  mutate(prop = n/sum(n))
```
]

--
.pull-right[
查看測試組的生病比例
```{r}
DM_test %>% 
  count(diabetes) %>% 
  mutate(prop = n/sum(n))
```
]

---
class: inverse, center, middle

# 開始建模 - 資料前處理

---
## Pre-Step 2. 建立資料前處理“食譜”

- 資料前處理也是建立兩種模型都必須經歷的方法
- 前處理包括將類別變項轉為虛擬變項(dummy variables)，數值變項取log，數值變項正規化，以及日期資料處理等

--
- 首先使用`recipe()`函數，設定模型訓練公式`diabetes ~ .`以及訓練用資料`DM_train`
  - 注意這邊只能用**訓練組資料**，不能用全部的資料
  - 公式：用`~`前方的`diabetes`當outcome (想要預測的值)，`~`後方的`.`代表其他所有剩下的欄位都當成predictors (又稱variables 或是 features)


```{r}
gen_recipe <- 
  recipe(diabetes ~ ., data = DM_train) %>% #<<
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())
summary(gen_recipe)
```

---
## Pre-Step 2. 建立資料前處理“食譜”

完成模型公式與資料設定後，就開始逐一加上想要做的資料前處理方法


- `step_dummy(all_nominal(), -all_outcomes())` 將所有的類別變項轉成虛擬變項，除了Outcome以外
- `step_zv(all_predictors())` 若有變項都是一樣的值，刪掉。舉例來說，若是整個資料都是女性，那性別欄位就不用拿來當作features了
- `step_normalize(all_predictors())` 將所有數值變項正規化

```{r}
gen_recipe <- 
  recipe(diabetes ~ ., data = DM_train) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>%  #<<
  step_zv(all_predictors()) %>% #<<
  step_normalize(all_predictors())#<<
summary(gen_recipe)
```

---
## Pre-Step 2. 建立資料前處理“食譜”
還有很多其他的前處理方法：
- `step_naomit(everything(), skip = TRUE)` 如果沒有在一開始將NA資料刪掉，通常要去除NA值
- `step_rose(diabetes)` 設定oversampleing或是undersampling，範例用ROSE作為oversampling的演算法
- 參考`recipe()`函數的[說明文件](https://recipes.tidymodels.org/reference/recipe.html)

```{r}
gen_recipe <- 
  recipe(diabetes ~ ., data = DM_train) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>%  
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())
summary(gen_recipe) #<<
```
---
class: inverse, center, middle

# 邏輯迴歸Logistic Regression模型建立與效能評估範例

---
## Step 1 設定用邏輯迴建立模型

- 以邏輯迴歸為例
- 用`logistic_reg()`函數指定使用邏輯迴歸
- 用`set_engine("glm")`設定模型建立演算法

```{r}
lr_mod <- 
  logistic_reg() %>% #<<
  set_engine("glm") #<<
```
---
## Step 2 設定建模流程workflow

將建模 (model，從step 1來的)與資料前處理方法 (recipe，從前處理來的)串成單一工作流程workflow

```{r}
lr_wflow <- 
  workflow() %>% #<<
  add_model(lr_mod) %>% #<<
  add_recipe(gen_recipe)#<<
lr_wflow
```

---
## Step 3 訓練模型

- 使用剛剛串起來的工作流程，加上`fit()`函數，完成建模

```{r}
lr_fit <- 
  lr_wflow %>% 
  fit(data=DM_train) #<<
```

---
## Step 3 訓練模型

- 使用剛剛串起來的工作流程，加上`fit()`函數，完成建模
```{r}
lr_fit <- 
  lr_wflow %>% 
  fit(data=DM_train) 
```

- 用`pull_workflow_fit()`與`tidy()`呈現建模結果，注意這裡也是只能用**訓練組資料**`DM_train`

```{r eval=FALSE}
lr_fit %>% 
  pull_workflow_fit() %>% #<<
  tidy() #<<
```
```{r echo=FALSE}
knitr::kable(head(lr_fit %>% 
  pull_workflow_fit() %>% 
  tidy()), format = 'html')
```

---
## Step 4 使用測試組資料驗證效能

- 剛剛訓練出來的模型`lr_fit`丟入`predict()`函數，指定以一開始分出的測試組`DM_test`產生預測結果
- 注意這邊**只能用測試組資料**`DM_test`

```{r}
lr_pred <- lr_fit %>% 
  predict(DM_test) #<<
```
```{r eval=FALSE}
lr_pred
```
```{r echo=FALSE}
knitr::kable(head(lr_pred), format = 'html')
```
---
## Step 4 使用測試組資料驗證效能
- 通常會直接將`predict()`函數預測結果與真實答案結合
- 答案為**測試組資料**`DM_test`中的diabetes欄位
- 將預測結果丟入`bind_cols()`，並指定與答案直接結合

```{r}
lr_pred <- lr_fit %>%
  predict(DM_test) %>% 
  bind_cols(DM_test %>% select(diabetes)) #<<
```
```{r eval=FALSE}
lr_pred
```
```{r echo=FALSE}
knitr::kable(head(lr_pred), format = 'html')
```
---
## Step 4 使用測試組資料驗證效能
使用`accuracy()`函數，輸入剛剛整合的**預測結果**與**真實答案**計算正確率

```{r}
lr_pred %>% 
  accuracy(truth = diabetes, #<<
          .pred_class)#<<
```

---
## Step 4 使用測試組資料驗證效能

- 很多時候我們需要回報**Area under the ROC curve**
- 此時不能直接採用模型預測pos或neg的結果
- 需要的連續性的預測數值來畫**ROC curve**
- 將`predict()`函數的`type`參數設定為prob，即回傳各組預測值

```{r}
lr_pred <- lr_fit %>%
  predict(DM_test,
          type = "prob")%>% #<<
  bind_cols(DM_test %>% select(diabetes)) 
```
```{r eval=FALSE}
lr_pred
```
```{r echo=FALSE}
knitr::kable(head(lr_pred), format = 'html')
```
---
## Step 4 使用測試組資料驗證效能
將預測結果`lr_pred`丟入`roc_curve()`，加上`autoplot()`畫ROC curve
```{r,out.height="350px",fig.align='center'}
lr_pred %>% 
  roc_curve(truth = diabetes, #<<
            .pred_pos) %>% #<<
  autoplot()#<<
```

---
## Step 4 使用測試組資料驗證效能
當然也能用`roc_auc()`算Area under the ROC curve

```{r eval=FALSE}
lr_pred %>% 
  roc_auc(truth = diabetes, #<<
          .pred_pos)#<<
```
```{r echo=FALSE}
knitr::kable(lr_pred %>% 
  roc_auc(truth = diabetes, 
          .pred_pos), 
  format = 'html')
```
---
## Step 5 解釋模型
- 以迴歸為例，參數即可解釋各變數與模型的關係
- 用`pull_workflow_fit()`與`tidy()`呈現建模結果

```{r eval=FALSE}
lr_fit %>% 
  pull_workflow_fit() %>% #<<
  tidy() #<<
```
```{r echo=FALSE}
knitr::kable(lr_fit %>% 
  pull_workflow_fit() %>% 
  tidy(), format = 'html')
```

---
# 完成
以上就是使用**邏輯迴歸**建立模型與效能測試流程，可以發現完全沒有調整任何參數，因基本邏輯迴歸不用調參數。

--

Pre-Step

1. 分訓練組測試組
2. 設定資料前處理方法

--

Step

1. 設定模型
2. 設定工作流程，串聯模型與資料前處理食譜
3. 建模
4. 得到預測效能
5. 解釋模型


---
class: inverse, center, middle

# 隨機森林Random Forest模型建立、參數調整與效能評估範例
---
## Step 1 設定平行處理

因為模型參數調整需要一直不斷建立模型與測試，所以設定平行處理會快一些，`tidymodels`套組支援平行處理，細節可參考[官方文件](https://tune.tidymodels.org/articles/extras/optimizations.html)

```{r message=F,warning=F}
library(parallel)
library(doParallel)
all_cores <- detectCores(logical = FALSE)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)
```

---
## Step 2 設定用隨機森林建立模型以及要調整的參數

- 用`rand_forest()`函數指定要建立隨機森林模型
- 用`set_engine("ranger")`設定模型建立演算法為基於`ranger`套件的隨機森林演算法，沒裝過`ranger`套件的話需要先裝
  - `permutation`: effect on the prediction performance (Mean decrease accuracy)
  - `impurity`: Gini index for classification 
- 因為隨機森林有迴歸版與分類版，因此使用`set_mode("classification")`設定我們要用分類演算法

```{r eval=F}
install.packages("ranger")
```

```{r}
rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), 
              trees = 1000) %>% 
  set_engine("ranger",
             importance= "permutation") %>% 
  set_mode("classification")
```

---
## Step 2 設定用隨機森林建立模型以及要調整的參數

在隨機森林`rand_forest()`函數中，可設定幾個參數，說明如下:

- mtry: 在切割節點時，隨機抽取n個特徵，並從中選最適合的特徵當作節點
- min_n: 每個節點的最小資料數，如果設為10，當該節點的資料剩十筆或更少時，就不會再切割
- trees: 建模要用幾棵樹

--

在這個範例中，我將要建幾棵樹設定為1000，其他兩個參數則是想用資料調整，因此將想調的參數值設為`tune()`，表示這些參數要調，不想在現階段指定。

```{r}
rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(),  #<<
              trees = 1000) %>% #<<
  set_engine("ranger",
             importance= "permutation") %>% 
  set_mode("classification")
```
---
## Step 2 設定用隨機森林建立模型以及要調整的參數
模型設定完成後，輸出如下
```{r}
rf_mod
```

---
## Step 3 設定建模流程workflow

建模流程同邏輯迴歸，將模型 (model，從step 2來的)與資料前處理方法(recipe，從前處理來的)串接成一個工作流程

```{r}
rf_wflow <- workflow() %>%
  add_model(rf_mod) %>%  #<<
  add_recipe(gen_recipe) #<<
rf_wflow
```

---
## Step 4 參數調整組資料分割

- 剛剛有提到要以資料調整的參數**mtry**以及**min_n**
- 首先將所有資料分成測試組訓練組，也就是本篇文章一開始做的切割
- 為了調整參數，再切訓練組資料，分成的**調整訓練**組以及**調整測試**組。
```{r echo=F,out.height="350px",fig.align='center'}
knitr::include_graphics("https://www.tidymodels.org/start/resampling/img/resampling.svg")
```
[圖片來源](https://www.tidymodels.org/start/resampling/)



---
## Step 4 參數調整組資料分割
- 切割**參數調整組**有很多種方法，可以用**bootstrap**法隨機抽，也可使用這邊的**交叉驗證**(Cross Validation)範例
- 圖片下半部為5-fold CV 的示意圖
- 每份資料都會被拿來當作**調整訓練**以及**調整測試**組
- 經過幾次測試後，用**調整測試**組的效能來決定一組最佳參數

```{r echo=F,out.height="350px",fig.align='center'}
knitr::include_graphics("https://www.frontiersin.org/files/Articles/411217/fmicb-09-02393-HTML/image_m/fmicb-09-02393-g002.jpg")
```
[圖片來源](https://doi.org/10.3389/fmicb.2018.02393)


---
## Step 4 參數調整組資料分割
- 使用10-fold CV 為例，先用`vfold_cv()`函數
  - 設定分割基準為**訓練組**`DM_train`
  - 要分10份`v=10`
  - 分割時要注意糖尿病的比例不能差太多，因此設為分組依據 `strata = diabetes`

```{r}
set.seed(345)
folds <- vfold_cv(DM_train, #<<
                  v = 10, #<<
                  strata = diabetes) #<<
folds
```
---
## Step 5 調整參數

- 將Step 3所建立的建模流程`rf_wflow`串接至`tune_grid()`函數，設定參數調整的方法
  - 設定切割好的**參數調整組**  `resamples = folds`
  - 要測試幾組參數   `grid = 50`
  - 測試時要用什麼效能評估方式，設定為Area under the ROC curve `metrics = metric_set(roc_auc)`
- 因為要重複訓練測試多次，因此這程式碼執行會需要一些時間。

```{r message=F,warning=F}
rf_res <- 
  rf_wflow %>% 
  tune_grid(
    resamples = folds,#<<
    grid = 50,#<<
    metrics = metric_set(roc_auc),#<<
    control=control_resamples(save_pred = TRUE)
    )
```

---
## Step 5 調整參數
執行完後，可用`collect_metrics()`查看各參數效能
```{r eval=FALSE}
rf_res %>%
  collect_metrics()#<<
```
```{r echo=FALSE}
knitr::kable(rf_res %>%
  collect_metrics() %>% head(), format = 'html')
```
---
## Step 5 調整參數
也可畫個圖呈現參數調整對效能的影響，由圖可知在這個範例中min_n越大效能越好

```{r,out.height="350px",fig.align='center'}
rf_res %>%
  collect_metrics() %>%
  mutate(mtry=factor(mtry)) %>%
  ggplot(aes(min_n, mean, color = mtry)) + 
  geom_line(size=1)
```
---
## Step 5 調整參數
搭配`show_best()`函數可呈現Area under the ROC curve最優的幾組參數

```{r eval=FALSE}
rf_res %>%
  show_best("roc_auc")#<<
```
```{r echo=FALSE}
knitr::kable(rf_res %>%
  show_best("roc_auc"), format = 'html')
```

---
## Step 6 使用最佳參數與訓練組資料建立最終模型

- 使用最佳參數(意即Area under the ROC curve最高的一組參數)來建立最終模型
- 將剛剛調參數的結果`rf_res`輸入`select_best()`函數，選出最好的一組參數`best_rf`

```{r}
best_rf <- rf_res %>%
  select_best("roc_auc")#<<
```
```{r eval=FALSE}
best_rf
```
```{r echo=FALSE}
knitr::kable(head(best_rf), format = 'html')
```
---
## Step 6 使用最佳參數與訓練組資料建立最終模型
將Step 3 建立的工作流程輸入`finalize_workflow()`函數，並指定要用剛剛選出的最佳參數`best_rf`，建立一個**最終建模流程**

```{r}
final_wflow <- 
  rf_wflow %>% 
  finalize_workflow(best_rf)#<<

final_wflow
```
---
## Step 6 使用最佳參數與訓練組資料建立最終模型
**最終建模流程** `final_wflow`建立後，即可用`fit()`建模，注意這邊用的是完整的訓練資料`DM_train`

```{r}
final_rf_model <- 
  final_wflow %>%
  fit(data = DM_train) #<<

final_rf_model
```

---
## Step 7 用測試組資料驗證最終效能

- 將剛剛訓練出來的模型`final_rf_model`輸入`predict()`函數
- 並指定使用一開始分出的測試組`DM_test`產生預測結果
- 注意要用**測試組資料**

```{r}
rf_pred <- final_rf_model %>% 
  predict(DM_test)#<<
```
```{r eval=FALSE}
rf_pred
```
```{r echo=FALSE}
knitr::kable(head(rf_pred), format = 'html')
```

---
## Step 7 用測試組資料驗證最終效能

- 通常會直接將`predict()`函數預測結果與真實答案結合
- 答案為**測試組資料**`DM_test`中的diabetes欄位
- 將預測結果丟入`bind_cols()`，並指定與答案直接結合
```{r}
rf_pred <- final_rf_model %>%
  predict(DM_test) %>% 
  bind_cols(DM_test %>% select(diabetes)) #<<
```
```{r eval=FALSE}
rf_pred
```
```{r echo=FALSE}
knitr::kable(head(rf_pred), format = 'html')
```
---
## Step 7 用測試組資料驗證最終效能
使用預測結果與真實答案計算正確率
```{r eval=FALSE}
rf_pred %>% 
  accuracy(truth = diabetes, #<<
          .pred_class) #<<
```
```{r echo=FALSE}
knitr::kable(rf_pred %>% 
  accuracy(truth = diabetes, 
          .pred_class),
  format = 'html')
```
---
## Step 7 用測試組資料驗證最終效能
- 很多時候我們需要回報**Area under the ROC curve**
- 此時不能直接採用模型預測pos或neg的結果
- 需要的連續性的預測數值來畫**ROC curve**
- 將`predict()`函數的`type`參數設定為prob，即回傳各組預測值

```{r}
rf_pred <- final_rf_model %>%
  predict(DM_test,
          type = "prob")%>% #<<
  bind_cols(DM_test %>% select(diabetes)) 
```
```{r eval=FALSE}
rf_pred
```
```{r echo=FALSE}
knitr::kable(head(rf_pred), format = 'html')
```
---
## Step 7 用測試組資料驗證最終效能
將預測結果`lr_pred`丟入`roc_curve()`，加上`autoplot()`畫ROC curve
```{r,out.height="350px",fig.align='center'}
rf_pred %>% 
  roc_curve(truth = diabetes, #<<
            .pred_pos) %>% #<<
  autoplot()#<<
```
---
## Step 7 用測試組資料驗證最終效能
當然也能用`roc_auc()`算Area under the ROC curve
```{r eval=FALSE}
rf_pred %>% 
  roc_auc(truth = diabetes, #<<
          .pred_pos)#<<
```
```{r echo=FALSE}
knitr::kable(rf_pred %>% 
  roc_auc(truth = diabetes, #<<
          .pred_pos), format = 'html')
```

---
## Step 8 解釋模型
- 查看最終模型`final_rf_model`中，各變數的重要性
- 用`pull_workflow_fit()`將模型資訊取出
- 丟入`vip()`查看各變數重要性
```{r warning=F, message=F,out.height="350px",fig.align='center'}
library(vip)
final_rf_model %>%
  pull_workflow_fit() %>%
  vi()
```
---
## Step 8 解釋模型
- 查看最終模型`final_rf_model`中，各變數的重要性
- 用`pull_workflow_fit()`將模型資訊取出
- 丟入`vip()`查看各變數重要性
```{r warning=F, message=F,out.height="350px",fig.align='center'}
library(vip)
final_rf_model %>%
  pull_workflow_fit() %>%
  vip()
```
---
# 完成
以上就是使用**隨機森林**建立模型、調整參數以及與效能測試流程，多了使用交叉驗證法調整參數的步驟。

--

Pre-Step

1. 分訓練組測試組
2. 設定資料前處理方法

--

Step

1. **設定平行處理**
2. 設定模型
3. 設定工作流程，串聯模型與資料前處理食譜
4. **切參數訓練組與參數測試組**
5. **調整參數，得到最佳參數**
6. **用最佳參數與訓練組建模**
7. 得到預測效能
8. 解釋模型

---
class: inverse, center, middle

# 正紅的XGBoost模型建立、參數調整與效能評估範例
---
## XGBoost不分步驟，一次搞定 (1/3)

```{r}
#install.packages("xgboost")
xgb_mod <- 
  boost_tree(mtry = tune(), #<<
             min_n = tune(), #<<
              trees = 1000) %>% #<<
  set_engine("xgboost",#<<
             importance= "permutation") %>% #<<
  set_mode("classification")
xgb_wflow <- workflow() %>%
  add_model(xgb_mod) %>%  
  add_recipe(gen_recipe) 
xgb_res <- 
  xgb_wflow %>% 
  tune_grid(
    resamples = folds,
    grid = 50,
    metrics = metric_set(roc_auc),
    control=control_resamples(save_pred = TRUE)
    )
```
---
## XGBoost不分步驟，一次搞定 (2/3)

```{r}
best_xgb <- xgb_res %>%
  select_best("roc_auc")
final_wflow <- 
  xgb_wflow %>% 
  finalize_workflow(best_xgb)
final_xgb_model <- 
  final_wflow %>%
  fit(data = DM_train) 
xgb_pred <- final_xgb_model %>%
  predict(DM_test,
          type = "prob")%>% 
  bind_cols(DM_test %>% select(diabetes)) 
```
---
## XGBoost不分步驟，一次搞定 (3/3)

```{r,out.height="400px",fig.align='center'}
xgb_pred %>% 
  roc_curve(truth = diabetes, 
            .pred_pos) %>% 
  autoplot()
```
---
class: inverse, center, middle
# 上課教的SVM模型建立、參數調整與效能評估範例
---
## SVM不分步驟，一次搞定 (1/3)

```{r}
#install.packages("kernlab")
svm_mod <- 
  svm_rbf(cost=tune(),#<<
          rbf_sigma=tune(),#<<
          margin=tune()) %>% #<<
  set_engine("kernlab",#<<
             importance= "permutation") %>% #<<
  set_mode("classification")
svm_wflow <- workflow() %>%
  add_model(svm_mod) %>%  
  add_recipe(gen_recipe) 
svm_res <- 
  svm_wflow %>% 
  tune_grid(
    resamples = folds,
    grid = 50,
    metrics = metric_set(roc_auc),
    control=control_resamples(save_pred = TRUE)
    )
```
---
## SVM不分步驟，一次搞定 (2/3)

```{r}
best_svm <- svm_res %>%
  select_best("roc_auc")
final_wflow <- 
  svm_wflow %>% 
  finalize_workflow(best_svm)
final_svm_model <- 
  final_wflow %>%
  fit(data = DM_train) 
svm_pred <- final_svm_model %>%
  predict(DM_test,
          type = "prob")%>% 
  bind_cols(DM_test %>% select(diabetes)) 
```

---
## SVM不分步驟，一次搞定 (3/3)

```{r,out.height="400px",fig.align='center'}
svm_pred %>% 
  roc_curve(truth = diabetes, 
            .pred_pos) %>% 
  autoplot()
```

---
# tidymodels總結

- [官方說明文件](https://www.tidymodels.org/)完整
- 建模、調參數、預測流程架構清楚
- 目前支援21大類模型，可透過[模型清單](https://www.tidymodels.org/find/parsnip/)查找，自行替換模型
- 不知道每個模型有何參數可調？一樣可透過[參數清單](https://www.tidymodels.org/find/parsnip/#model-args)查找
- 不知道參數意義？了解各模型的原理還是很重要的！

---
## 訓練/調整與驗證模型效能策略
```{r echo=F,out.height="500px",fig.align='center'}
knitr::include_graphics("https://cdn.jamanetwork.com/ama/content_public/journal/jama/938259/jug190001f2.png?Expires=2147483647&Signature=cU6lP2ZYSdn9MyOakMWobXQF2h6LSPCExTP1q7x74zRH7gDgkRSqshXWADmcQUz0XJVK~aVPK3cb-~shWQ6vd6EF4FwIcR8NBXMlGq1sLDR5dXLwpb~qoEYzXvg03zCz2l0AHmdlFxy4IGYGG3ilBfuPh1SCweskxtaUfsWqGsUcwc6FNo3KjaR9j58eJeZOnBEr6a2OF2m~XlEOnT1W3vaYn2-fuGZLAQR88XcUGWp1LYgc6GnDTO1s7zj5m9mYhlL-CeOaLXQNGrSl6fAvw6LisZW-f2tChvIaDfCd4vuuNw-Q1V6sjm-jgUehMt8wjrc61YW6WqyIC9mF6VGzzg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA")
```

---
## 訓練/調整與驗證模型效能步驟

Pre-Step

1. 分訓練組測試組
2. 設定資料前處理方法

Step

1. **設定平行處理**
2. 設定模型
3. 設定工作流程，串聯模型與資料前處理食譜
4. **切參數訓練組與參數測試組**
5. **調整參數，得到最佳參數**
6. **用最佳參數與訓練組建模**
7. 得到預測效能
8. 解釋模型


